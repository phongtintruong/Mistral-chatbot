{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import HTML, display\n\ndef set_css():\n  display(HTML('''\n  <style>\n    pre {\n        white-space: pre-wrap;\n    }\n  </style>\n  '''))\n\nget_ipython().events.register('pre_run_cell', set_css)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T13:10:12.420498Z","iopub.execute_input":"2023-12-07T13:10:12.420845Z","iopub.status.idle":"2023-12-07T13:10:12.429195Z","shell.execute_reply.started":"2023-12-07T13:10:12.420814Z","shell.execute_reply":"2023-12-07T13:10:12.428258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:10:16.073109Z","iopub.execute_input":"2023-12-07T13:10:16.073784Z","iopub.status.idle":"2023-12-07T13:12:10.285624Z","shell.execute_reply.started":"2023-12-07T13:10:16.073735Z","shell.execute_reply":"2023-12-07T13:12:10.284464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:12:15.250886Z","iopub.execute_input":"2023-12-07T13:12:15.251264Z","iopub.status.idle":"2023-12-07T13:12:18.478136Z","shell.execute_reply.started":"2023-12-07T13:12:15.251222Z","shell.execute_reply":"2023-12-07T13:12:18.477111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:12:23.683634Z","iopub.execute_input":"2023-12-07T13:12:23.684533Z","iopub.status.idle":"2023-12-07T13:14:32.243142Z","shell.execute_reply.started":"2023-12-07T13:12:23.684495Z","shell.execute_reply":"2023-12-07T13:14:32.242187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:15:07.314167Z","iopub.execute_input":"2023-12-07T13:15:07.315080Z","iopub.status.idle":"2023-12-07T13:15:07.327239Z","shell.execute_reply.started":"2023-12-07T13:15:07.315028Z","shell.execute_reply":"2023-12-07T13:15:07.326394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:15:25.436360Z","iopub.execute_input":"2023-12-07T13:15:25.437179Z","iopub.status.idle":"2023-12-07T13:15:25.447845Z","shell.execute_reply.started":"2023-12-07T13:15:25.437143Z","shell.execute_reply":"2023-12-07T13:15:25.446952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda:0\"\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Do you have mayonnaise recipes?\"}\n]\n\n\nencodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n\nmodel_inputs = encodeds.to(device)\n\n\ngenerated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\ndecoded = tokenizer.batch_decode(generated_ids)\nprint(decoded[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:15:35.419449Z","iopub.execute_input":"2023-12-07T13:15:35.420396Z","iopub.status.idle":"2023-12-07T13:16:16.828994Z","shell.execute_reply.started":"2023-12-07T13:15:35.420355Z","shell.execute_reply":"2023-12-07T13:16:16.827957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/my_model\")  # Save to a directory in Kaggle workspace\ntokenizer.save_pretrained(\"/kaggle/working/my_model\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T13:29:34.223016Z","iopub.execute_input":"2023-12-07T13:29:34.223812Z","iopub.status.idle":"2023-12-07T13:29:35.430105Z","shell.execute_reply.started":"2023-12-07T13:29:34.223775Z","shell.execute_reply":"2023-12-07T13:29:35.428860Z"},"trusted":true},"execution_count":null,"outputs":[]}]}